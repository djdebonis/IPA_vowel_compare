{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_read(infile_path_and_name):\n",
    "    \"\"\"\n",
    "    opens a file and returns a long long long string\n",
    "    \n",
    "    :infile_path_and_name: string of the path/path/txtFileName.txt from the current directory\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    with open(infile_path_and_name, 'r') as file:\n",
    "        variable = file.read().replace('\\n', '')\n",
    "        \n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(sentence: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes a sentence in IPA and parses it to individual words by breaking according to\n",
    "    the \" # \" IPA string pattern.\n",
    "    \n",
    "    :sentence: sentence to parse\n",
    "    \n",
    "    :returns: list of individual words\n",
    "    :rtype: list\n",
    "    \n",
    "    \"\"\"\n",
    "    words = sentence.split(\" # \")\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_stress(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of strings in IPA that contain prosodic accent marks and removes\n",
    "    the dashes to clean the data.\n",
    "    \n",
    "    :word_list: list of strings\n",
    "    \n",
    "    :returns: list of strings without prosodic accent marks\n",
    "    :rtype: list of strings\n",
    "    \n",
    "    \"\"\"\n",
    "    new_list = []\n",
    "    for s in range(len(word_list)):\n",
    "        word = word_list[s]\n",
    "        new_word = re.compile(r\"'\").sub(\"\",word)\n",
    "        new_list.append(new_word)\n",
    "    return(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllabize_further(word: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes a string with syllable hyphens and breaks it apart into a list of syllables\n",
    "    \n",
    "    :word: str: word form with hyphens marking syllable\n",
    "    \n",
    "    :returns: list of individual syllables\n",
    "    :rtype: list\n",
    "    \n",
    "    \"\"\"\n",
    "    syllables = word.split(\"-\")\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_lists_append(prescrip_string, descrip_string, prescrip_vowel_ls, descrip_vowel_ls):\n",
    "    \"\"\"\n",
    "    Takes two lists of strings and two strings and appends the vowels of the new strings on to the list of vowels\n",
    "    \n",
    "    :prescrip_string: the syllable with the 'correct' vowell\n",
    "    :descrip_string: the syllable with the student's pronunciation of the vowel\n",
    "    :prescrip_vowel_ls: the list of all of the 'correct' vowel pronunciations\n",
    "    :descrip_vowel_ls: the list with all of the student's pronunciations of the vowels\n",
    "    \n",
    "    \n",
    "    :returns: dataframe with lots of good data\n",
    "    :rtype: pandas DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    long_vowel_list = ['a:','e:','i:','o:','u:','ɛ:','æ:','ə:','ʌ:','ɪ:','ɔ:','ɑ:','ʊ:']\n",
    "    diphthong_list =['au̯','eu̯','iu̯','ou̯','uu̯','ɛu̯','æu̯','əu̯','ʌu̯','ɪu̯','ɔu̯','ɑu̯','ʊu̯',\n",
    "                     'ai̯','ei̯','ii̯','oi̯','ui̯','ɛi̯','æi̯','əi̯','ʌi̯','ɪi̯','ɔi̯','ɑi̯','ʊi̯',\n",
    "                     'i̯a','i̯e','i̯i','i̯o','i̯u','i̯ɛ','i̯æ','i̯ə','i̯ʌ','i̯ɪ','i̯ɔ','i̯ɑ','i̯ʊ',\n",
    "                     'u̯a','u̯e','u̯i','u̯o','u̯u','u̯ɛ','u̯æ','u̯ə','u̯ʌ','u̯ɪ','u̯ɔ','u̯ɑ','u̯ʊ']\n",
    "                             \n",
    "    vowel_list = ['a', 'e', 'i', 'o', 'u']\n",
    "    semivowwel_list =['i̯','u̯',]\n",
    "    pure_vowel_list = ['a','e','i','o','u','ɛ','æ','ə','ʌ','ɪ','ɔ','ɑ','ʊ']\n",
    "\n",
    "    boolean = True\n",
    "    \n",
    "    while boolean == True:\n",
    "        if boolean == True:\n",
    "            for s in range(len(diphthong_list)):\n",
    "                if diphthong_list[s] in prescrip_string:\n",
    "                    prescrip_vowel_ls.append(diphthong_list[s])\n",
    "                    boolean = False\n",
    "                    break\n",
    "                else:\n",
    "                    boolean = True\n",
    " \n",
    "\n",
    "            if boolean == True:\n",
    "                for i in range(len(vowel_list)):\n",
    "                    if vowel_list[i] in prescrip_string:\n",
    "                        prescrip_vowel_ls.append(vowel_list[i])\n",
    "                        boolean = False\n",
    "                        break\n",
    "                    else:\n",
    "                        boolean = True\n",
    "        \n",
    "    \n",
    "    boolean1 = True\n",
    "    \n",
    "    while boolean1 == True:\n",
    "        \n",
    "        if boolean1 == True:\n",
    "            for j in range(len(long_vowel_list)):\n",
    "                if long_vowel_list[j] in descrip_string:\n",
    "                    descrip_vowel_ls.append(long_vowel_list[j])\n",
    "                    boolean1 = False\n",
    "                    break\n",
    "\n",
    "            if boolean1 == True:\n",
    "                for q in range(len(diphthong_list)):\n",
    "                    if diphthong_list[q] in descrip_string:\n",
    "                        descrip_vowel_ls.append(diphthong_list[q])\n",
    "                        boolean1 = False\n",
    "                        break\n",
    "\n",
    "            if boolean1 == True:\n",
    "                for z in range(len(pure_vowel_list)):\n",
    "                    if pure_vowel_list[z] in descrip_string:\n",
    "                        descrip_vowel_ls.append(pure_vowel_list[z])\n",
    "                        boolean1 = False\n",
    "                        break\n",
    "\n",
    "\n",
    "    \n",
    "    #print(\"Prescriptive vowel list:\")\n",
    "    #print(prescrip_vowel_ls)\n",
    "    #print(\"Descriptive vowel list:\")\n",
    "    #print(descrip_vowel_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive_ls = ['a:']\n",
    "#prescriptive_ls = ['a']\n",
    "\n",
    "#descriptive = 'hei̯'\n",
    "#prescriptive = 'hee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_list_phoneme_compare(response,answer):\n",
    "    \"\"\"\n",
    "    Takes two lists of (IPA) strings--the student response (response) and the correct answer (answer)--\n",
    "    and compares them against eachother. Then, the function will (1) find mismatches, and \n",
    "    (2) return the word, the string index, the correct allophone, and the discrepancy (i.e. the incorrect \n",
    "    allophone[s].)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    response : list of strings\n",
    "    answer : list of strings\n",
    "    \n",
    "    AS OF RIGHT NOW:\n",
    "        (1) lists of strings must be of equal length\n",
    "        (2) the number of syllables per string must be of equal length\n",
    "            \n",
    "    \n",
    "    :returns: a table with the aforementioned data\n",
    "    :rtype: dataframe \n",
    "    \n",
    "    \"\"\"\n",
    "    word_index = []\n",
    "    word = []\n",
    "    student_pronunciation = []\n",
    "    indexes = []\n",
    "    student_allophones = []\n",
    "    prescriptive_allophones = []\n",
    "    binary = []\n",
    "    \n",
    "    p_syllable_lengths = []\n",
    "    d_syllable_lengths = []\n",
    "    \n",
    "    syllable_header =[]\n",
    "    p_syllables = []\n",
    "    d_syllables = []\n",
    "    syllable_number =[]\n",
    "    \n",
    "    if len(response) == len(answer):\n",
    "        \n",
    "        for s in range(len(response)): # first nested loop iterates through the strings in the list\n",
    "\n",
    "            # assign variables to both of the strings because you will be appending them multiple times later on\n",
    "            answer_word = answer[s]\n",
    "            response_word = response[s]\n",
    "\n",
    "            # break each string into a smaller list of individual syllables\n",
    "            d_list_of_syllables = syllabize_further(response[s]) \n",
    "            p_list_of_syllables = syllabize_further(answer[s])\n",
    "\n",
    "            #p_syllables[s] = p_list_of_syllables\n",
    "            #d_syllables[s] = d_list_of_syllables\n",
    "\n",
    "            if len(d_list_of_syllables) == len(p_list_of_syllables): # check to see if there are the same amount of syllables inside each word\n",
    "\n",
    "                for j in range(len(p_list_of_syllables)): # now iterating through each syllable in the word list (j = syllable number)\n",
    "\n",
    "                    # assign each syllable to a unique string variable for further iteration\n",
    "                    descriptive_syllable = d_list_of_syllables[j]\n",
    "                    prescriptive_syllable = p_list_of_syllables[j]\n",
    "\n",
    "                    vowel_lists_append(prescriptive_syllable, descriptive_syllable, prescriptive_allophones, student_allophones)\n",
    "\n",
    "                    word_index.append(s)\n",
    "                    word.append(answer_word)\n",
    "                    student_pronunciation.append(response_word)\n",
    "                    syllable_number.append(j)\n",
    "                    d_syllables.append(descriptive_syllable)\n",
    "                    p_syllables.append(prescriptive_syllable)\n",
    "                    \n",
    "\n",
    "            else:\n",
    "                print(\"Word \" + (str(s)) + \" in the student response has the wrong number of syllables.\" )\n",
    "\n",
    "\n",
    "    #else:\n",
    "        #print(\"The two lists do not contain the same amount of strings.\")\n",
    "\n",
    "    data = pd.DataFrame(list(zip(word_index, word, student_pronunciation, syllable_number, p_syllables, d_syllables, prescriptive_allophones,\n",
    "                                 student_allophones)), columns =['word_number','prescriptive_pronunciation','student_pronunciation','syllable_number','prescriptive_syllable','student_syllable','correct_allophone','student_allophone'])\n",
    "        \n",
    "   \n",
    "            \n",
    "\n",
    "    return(data)\n",
    "                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasheet_compile(list_of_lists, prescriptive_list):\n",
    "    \"\"\"\n",
    "    Takes a list of lists of strings and turns them into a list of dataframes that contain all of the information we are looking for\n",
    "    (see string_list_phoneme_compare function for more information)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :list_of_lists: a list of lists of strings; all lists must be the same length\n",
    "    :prescriptive_list: a list of strings; prescriptive list must be same len as all lists in list_of_lists\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    :returns: list of dataframes with all of the good data we want\n",
    "    :rtype: list of pandas DataFrames\n",
    "    \n",
    "    \"\"\"\n",
    "    ls_of_dfs = []\n",
    "    for i in range(len(list_of_lists)):\n",
    "        current_list = list_of_lists[i]\n",
    "        current_df = string_list_phoneme_compare(current_list, prescriptive_list)\n",
    "        ls_of_dfs.append(current_df)\n",
    "        \n",
    "    return(ls_of_dfs)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_dictionary(dictionary_df, column_criteria, equivelancy_criteria, ls_of_dfs):\n",
    "    \"\"\"\n",
    "    Uses the categorical/meta information from one dataframe (in this case, the dictionary dataframe), and uses some criteria\n",
    "    within it to filter another dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :dictionary_df: a pandas DataFrame with information relating to how you might want to filter the df\n",
    "    :column_criteria: a string that is the column name of what you want to filter by in in dictionary_df\n",
    "    :equivelancy_criteria: what the cells in dictionary_df[column_criteria] are equal to (e.g. 1, False, \"<a>\", etc.)\n",
    "    :ls_of_dfs: a list of pandas DataFrames that you want to filter by some criteria\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    :returns: a list of filtered dataframes\n",
    "    :rtype: list of pd DataFrames\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    word_selects = dictionary_df[dictionary_df[column_criteria] == equivelancy_criteria]\n",
    "    \n",
    "    new_ls_of_dfs = []\n",
    "    \n",
    "    for i in range(len(ls_of_dfs)):\n",
    "        temp_df = ls_of_dfs[i]\n",
    "        temp_df = temp_df[temp_df['word_number'].isin(word_selects['list_number'])]\n",
    "        new_ls_of_dfs.append(temp_df)\n",
    "        \n",
    "    return(new_ls_of_dfs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_allophone(ls_of_dfs, allophone):\n",
    "    \"\"\"\n",
    "    Filter the entire list of dataframes by a specific allophone.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :allophone: the allophone that you want to focus on, e.g. 'a', 'e', etc.\n",
    "    :ls_of_dfs: a list of pandas DataFrames that you want to filter by some criteria\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    :returns: a list of filtered dataframes\n",
    "    :rtype: list of pd DataFrames\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    new_ls_of_dfs = []\n",
    "    \n",
    "    for i in range(len(ls_of_dfs)):\n",
    "        temp_df = ls_of_dfs[i]\n",
    "        temp_df = temp_df[temp_df['correct_allophone'] == allophone] # right now the code doesn't account for any diphtongs\n",
    "        new_ls_of_dfs.append(temp_df)\n",
    "        \n",
    "    return(new_ls_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportions(ls_of_dfs):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    ls_of_proportions = []\n",
    "    \n",
    "    for i in range(len(ls_of_dfs)):\n",
    "        temp_df = ls_of_dfs[i]\n",
    "        \n",
    "        boolean = temp_df['correct_allophone'] == temp_df['student_allophone']\n",
    "        denominat = len(boolean)\n",
    "        numerat = boolean.sum()\n",
    "        proportion = numerat/denominat\n",
    "        \n",
    "        ls_of_proportions.append(proportion)\n",
    "        \n",
    "    return(ls_of_proportions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptive_string = open_and_read(\"transcriptions/prescriptive_ls.txt\") # import transcription.txt files as strings\n",
    "partic01_string = open_and_read(\"transcriptions/partic01.txt\")\n",
    "partic02_string = open_and_read(\"transcriptions/partic02.txt\")\n",
    "partic03_string = open_and_read(\"transcriptions/partic03.txt\")\n",
    "partic04_string = open_and_read(\"transcriptions/partic04.txt\")\n",
    "partic05_string = open_and_read(\"transcriptions/partic05.txt\")\n",
    "partic07_string = open_and_read(\"transcriptions/partic07.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptive_raw = split_sentence(prescriptive_string) # split strings into individual words: lists of strings\n",
    "partic01_raw = split_sentence(partic01_string)\n",
    "partic02_raw = split_sentence(partic02_string)\n",
    "partic03_raw = split_sentence(partic03_string)\n",
    "partic04_raw = split_sentence(partic04_string)\n",
    "partic05_raw = split_sentence(partic05_string)\n",
    "partic07_raw = split_sentence(partic07_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptive = rm_stress(prescriptive_raw) # clean data of any prosodic accent marks\n",
    "partic01 = rm_stress(partic01_raw)\n",
    "partic02 = rm_stress(partic02_raw)\n",
    "partic03 = rm_stress(partic03_raw)\n",
    "partic04 = rm_stress(partic04_raw)\n",
    "partic05 = rm_stress(partic05_raw)\n",
    "partic07 = rm_stress(partic07_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_number</th>\n",
       "      <th>prescriptive_pronunciation</th>\n",
       "      <th>student_pronunciation</th>\n",
       "      <th>syllable_number</th>\n",
       "      <th>prescriptive_syllable</th>\n",
       "      <th>student_syllable</th>\n",
       "      <th>correct_allophone</th>\n",
       "      <th>student_allophone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i-se</td>\n",
       "      <td>i-se</td>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i-se</td>\n",
       "      <td>i-se</td>\n",
       "      <td>1</td>\n",
       "      <td>se</td>\n",
       "      <td>se</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>0</td>\n",
       "      <td>kom</td>\n",
       "      <td>kom</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>1</td>\n",
       "      <td>bi</td>\n",
       "      <td>bi</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>2</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_number prescriptive_pronunciation student_pronunciation  \\\n",
       "0            0                       i-se                  i-se   \n",
       "1            0                       i-se                  i-se   \n",
       "2            1            kom-bi-na-si̯on       kom-bi-na-si̯on   \n",
       "3            1            kom-bi-na-si̯on       kom-bi-na-si̯on   \n",
       "4            1            kom-bi-na-si̯on       kom-bi-na-si̯on   \n",
       "\n",
       "   syllable_number prescriptive_syllable student_syllable correct_allophone  \\\n",
       "0                0                     i                i                 i   \n",
       "1                1                    se               se                 e   \n",
       "2                0                   kom              kom                 o   \n",
       "3                1                    bi               bi                 i   \n",
       "4                2                    na               na                 a   \n",
       "\n",
       "  student_allophone  \n",
       "0                 i  \n",
       "1                 e  \n",
       "2                 o  \n",
       "3                 i  \n",
       "4                 a  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_data = datasheet_compile(data,prescriptive) # turn the list of lists of strings into a list of dataframes\n",
    "study_data[1].head() # print a small amount as demonstraation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [partic01,partic02,partic03,partic04,partic05,partic07] # compile the lists of strings into ANOTHER LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partic_number</th>\n",
       "      <th>age</th>\n",
       "      <th>self_identify</th>\n",
       "      <th>spanish_travel</th>\n",
       "      <th>travel_abroad</th>\n",
       "      <th>heritage_exposure</th>\n",
       "      <th>formal_instruct</th>\n",
       "      <th>years_formal_instruct</th>\n",
       "      <th>explicit_pronunciation</th>\n",
       "      <th>spanish_exposure</th>\n",
       "      <th>spanish_production</th>\n",
       "      <th>last_spanish</th>\n",
       "      <th>learn_spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partic10</td>\n",
       "      <td>20</td>\n",
       "      <td>Intermediate-Advanced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>This month</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partic04</td>\n",
       "      <td>21</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>This week</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partic05</td>\n",
       "      <td>47</td>\n",
       "      <td>Beginner-Intermediate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>This week</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>partic02</td>\n",
       "      <td>28</td>\n",
       "      <td>Beginner-Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Almost never</td>\n",
       "      <td>It's been a long time</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>partic03</td>\n",
       "      <td>21</td>\n",
       "      <td>Beginner-Intermediate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>This week</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>partic06</td>\n",
       "      <td>27</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Almost never</td>\n",
       "      <td>It's been a long time</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>partic01</td>\n",
       "      <td>20</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Almost never</td>\n",
       "      <td>Almost never</td>\n",
       "      <td>It's been a long time</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>partic07</td>\n",
       "      <td>46</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>This year</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>partic08</td>\n",
       "      <td>19</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>This month</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>partic09</td>\n",
       "      <td>17</td>\n",
       "      <td>Beginner-Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>This week</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partic_number  age          self_identify spanish_travel travel_abroad  \\\n",
       "0      partic10   20  Intermediate-Advanced            Yes            No   \n",
       "1      partic04   21               Advanced             No            No   \n",
       "2      partic05   47  Beginner-Intermediate            Yes            No   \n",
       "3      partic02   28  Beginner-Intermediate             No            No   \n",
       "4      partic03   21  Beginner-Intermediate            Yes            No   \n",
       "5      partic06   27               Beginner            Yes            No   \n",
       "6      partic01   20               Beginner            Yes            No   \n",
       "7      partic07   46           Intermediate            Yes            No   \n",
       "8      partic08   19               Advanced            Yes            No   \n",
       "9      partic09   17  Beginner-Intermediate             No            No   \n",
       "\n",
       "  heritage_exposure formal_instruct  years_formal_instruct  \\\n",
       "0                No             Yes                   7.00   \n",
       "1                No             Yes                   7.00   \n",
       "2                No              No                   0.00   \n",
       "3                No             Yes                   3.00   \n",
       "4                No             Yes                   3.00   \n",
       "5                No             Yes                   0.02   \n",
       "6                No             Yes                   2.00   \n",
       "7                No             Yes                   4.00   \n",
       "8                No             Yes                   5.00   \n",
       "9                No             Yes                   3.00   \n",
       "\n",
       "  explicit_pronunciation spanish_exposure spanish_production  \\\n",
       "0                    Yes        Sometimes          Sometimes   \n",
       "1                    Yes              NaN             Rarely   \n",
       "2                     No        Sometimes             Rarely   \n",
       "3                    Yes        Sometimes       Almost never   \n",
       "4                    Yes           Rarely          Sometimes   \n",
       "5                    Yes        Sometimes       Almost never   \n",
       "6                    Yes     Almost never       Almost never   \n",
       "7                    Yes           Rarely             Rarely   \n",
       "8                    Yes           Rarely          Sometimes   \n",
       "9                    Yes           Rarely             Rarely   \n",
       "\n",
       "            last_spanish learn_spanish  \n",
       "0             This month           Yes  \n",
       "1              This week            No  \n",
       "2              This week           Yes  \n",
       "3  It's been a long time           Yes  \n",
       "4              This week            No  \n",
       "5  It's been a long time            No  \n",
       "6  It's been a long time            No  \n",
       "7              This year            No  \n",
       "8             This month           Yes  \n",
       "9              This week           Yes  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data = pd.read_csv(\"survey_data.csv\")\n",
    "survey_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 3.0, 3.0, 7.0, 0.0, 4.0]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_numbers = [6,3,4,1,2,7]\n",
    "years_instruct = []\n",
    "\n",
    "for i in range(len(index_numbers)):\n",
    "    integer = index_numbers[i]\n",
    "    years = survey_data['years_formal_instruct'][integer]\n",
    "    years_instruct.append(years)\n",
    "\n",
    "years_instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vowel_focus1</th>\n",
       "      <th>vowel_focus2</th>\n",
       "      <th>init_vowel</th>\n",
       "      <th>term_vowel</th>\n",
       "      <th>cognate</th>\n",
       "      <th>list_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taza</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sabe</td>\n",
       "      <td>e</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>casi</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word vowel_focus1 vowel_focus2  init_vowel  term_vowel  cognate  \\\n",
       "0  taza            a          NaN           0           1        0   \n",
       "1  sabe            e            a           0           1        0   \n",
       "2  casi            i            a           0           1        0   \n",
       "\n",
       "   list_number  \n",
       "0           20  \n",
       "1           13  \n",
       "2            6  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = pd.read_csv(\"dictionary.csv\") # import the dictionary for meta-data on specific words\n",
    "dictionary.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in set that are vowel initial: 15\n",
      "Words in set that are terminal vowel: 17\n",
      "Words in set that are cognates: 6\n"
     ]
    }
   ],
   "source": [
    "# some simple descriptive stats about the words in the current list\n",
    "vowel_init = dictionary[dictionary['init_vowel'] == 1] # count vowel-initial words in df\n",
    "vowel_init_count = len(vowel_init)\n",
    "print(\"Words in set that are vowel initial: \" + str(vowel_init_count))\n",
    "\n",
    "term_vowel = dictionary[dictionary['term_vowel'] == 1]\n",
    "term_vowel_count = len(term_vowel)\n",
    "print(\"Words in set that are terminal vowel: \" + str(term_vowel_count))\n",
    "\n",
    "cognates = dictionary[dictionary['cognate'] == 1]\n",
    "cognates_count = len(cognates)\n",
    "print(\"Words in set that are cognates: \" + str(cognates_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the allophone 'e,' the participants scored an average of 0.47222222222222227 with a std of 0.11453071182271278\n"
     ]
    }
   ],
   "source": [
    "e_accuracy = get_proportions(e_dfs)\n",
    "e_accuracy_mean = np.mean(e_accuracy)\n",
    "e_accuracy_std = np.std(e_accuracy)\n",
    "print(\"For the allophone 'e,' the participants scored an average of \" + str(e_accuracy_mean) + \" with a std of \" + str(e_accuracy_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, he particpants scored an average of 0.7711864406779662 accuracy with std of: 0.12329464882935139\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = get_proportions(study_data)\n",
    "total_accuracy_mean = np.mean(total_accuracy)\n",
    "total_accuracy_std = np.std(total_accuracy)\n",
    "print(\"In total, he particpants scored an average of \" + str(total_accuracy_mean) +\n",
    "      \" accuracy with std of: \" + str(total_accuracy_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For cognates, the particpants scored an average of 0.7575757575757577 accuracy with std of: 0.1975515880364439\n"
     ]
    }
   ],
   "source": [
    "cognate_dfs = filter_by_dictionary(dictionary, \"cognate\", 1, study_data) # create a list of dfs that only accounts for the cognates in the study\n",
    "cognate_accuracy = get_proportions(cognate_dfs)\n",
    "cognate_accuracy\n",
    "cognate_accuracy_mean = np.mean(cognate_accuracy)\n",
    "cognate_accuracy_std = np.std(cognate_accuracy)\n",
    "print(\"For cognates, the particpants scored an average of \" + str(cognate_accuracy_mean) +\n",
    "      \" accuracy with std of: \" + str(cognate_accuracy_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x119dc6e80>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(years_instruct, total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(ls_of_dfs, allophone):\n",
    "    \"\"\"\n",
    "    Returns some basic descriptive statistics about the selected allophone in the input dataframes.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    new_ls_dfs = filter_by_allophone(ls_of_dfs, allophone)\n",
    "    allophone_frequency = len(new_ls_dfs[0])\n",
    "    \n",
    "    print(\"In this word list, the allophone [\" + allophone + \"] occured in \" + str(allophone_frequency) + \" syllables.\")\n",
    "    \n",
    "    accuracy_ls = get_proportions(new_ls_dfs)\n",
    "    accuracy_mean = np.mean(accuracy_ls)\n",
    "    accuracy_std = np.std(accuracy_ls)\n",
    "    \n",
    "    print(\"For this allophone:\")\n",
    "    print(\"The particpants scored an average of \" + str(accuracy_mean * 100) +\n",
    "      \"% accuracy with standard deviation of: \" + str(accuracy_std * 100) + \"%\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    allophonic_errors = []\n",
    "    nex_ls_dfs = []\n",
    "    \n",
    "    for i in range(len(ls_of_dfs)):\n",
    "        temp_df = new_ls_dfs[i]\n",
    "        errors_df = temp_df[temp_df['correct_allophone'] != temp_df['student_allophone']]\n",
    "        #print(errors_df)\n",
    "        nex_ls_dfs.append(errors_df)\n",
    "        \n",
    "        \n",
    "    for j in range(len(nex_ls_dfs)):\n",
    "        errors = nex_ls_dfs[j]['student_allophone']\n",
    "        errors_ls = list(errors)\n",
    "        print(errors_ls)\n",
    "        \n",
    "        #for s in range(len(errors_ls)):\n",
    "         #   error = errors_ls[s]\n",
    "          #  allophonic_errors.append(error)\n",
    "            \n",
    "    \n",
    "    return(allophonic_errors)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this word list, the allophone [e] occured in 12 syllables.\n",
      "For this allophone:\n",
      "The particpants scored an average of 47.22222222222223% accuracy with standard deviation of: 11.453071182271279%\n",
      "\n",
      "['ei̯', 'ɛ', 'ei̯', 'ɛ', 'i', 'ɛ', 'ei̯', 'ɛ']\n",
      "['ɛ', 'ɛ', 'ɛ', 'ɛ']\n",
      "['ɛ', 'ɛ', 'ɛ', 'ʌ', 'ɛ', 'ɛ']\n",
      "['ɛ', 'ɛ', 'ei̯', 'ɛ', 'ei̯', 'ɛ']\n",
      "['ei̯', 'ɛ', 'ɛ', 'ɛ', 'ɛ', 'ei̯']\n",
      "['ei̯', 'ɛ', 'ei̯', 'ɛ', 'ɛ', 'ɛ', 'ei̯', 'ɛ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(study_data, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this word list, the allophone [a] occured in 21 syllables.\n",
      "The particpants scored an average of 86.5079365079365% accuracy with standard deviation of: 15.409910983291747%\n",
      "\n",
      "['i', 'ei̯', 'a:', 'ʌ', 'a:', 'æ', 'a:', 'ə', 'ɛ']\n",
      "[]\n",
      "['ɪ', 'æ', 'ai̯', 'ə', 'ʌ']\n",
      "[]\n",
      "['ə', 'ə']\n",
      "['ʌ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(study_data, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this word list, the allophone [i] occured in 11 syllables.\n",
      "The particpants scored an average of 75.75757575757576% accuracy with standard deviation of: 17.92751449424126%\n",
      "\n",
      "['ɪ', 'i̯a', 'i̯ɔ', 'o', 'ɪ', 'ɪ']\n",
      "[]\n",
      "['ɪ', 'ɪ', 'o', 'ɪ']\n",
      "['i:', 'ɪ', 'ɪ']\n",
      "['ou̯', 'i̯u']\n",
      "['ɪ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(study_data, 'i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this word list, the allophone [u] occured in 6 syllables.\n",
      "The particpants scored an average of 88.8888888888889% accuracy with standard deviation of: 12.422599874998832%\n",
      "\n",
      "['uu̯']\n",
      "[]\n",
      "['ə']\n",
      "['ə', 'uu̯']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(study_data,'u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this word list, the allophone [o] occured in 13 syllables.\n",
      "The particpants scored an average of 84.61538461538461% accuracy with standard deviation of: 17.200522903844536%\n",
      "\n",
      "['i̯a', 'i̯ɔ', 'o', 'a', 'ə', 'ou̯']\n",
      "[]\n",
      "['a', 'o', 'a']\n",
      "[]\n",
      "['ou̯', 'i̯u', 'ə']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(study_data,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word vowel_focus1 vowel_focus2  init_vowel  term_vowel  cognate  \\\n",
      "6     educación            e            u           1           0        1   \n",
      "7    importante            i            e           1           1        1   \n",
      "8   oportunidad            o            i           1           0        1   \n",
      "9          usar            u          NaN           1           0        1   \n",
      "16    funcionar            u            o           0           0        1   \n",
      "17  combinación            a            i           0           0        1   \n",
      "\n",
      "    list_number  \n",
      "6             3  \n",
      "7            21  \n",
      "8            14  \n",
      "9             7  \n",
      "16            8  \n",
      "17            1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_number</th>\n",
       "      <th>prescriptive_pronunciation</th>\n",
       "      <th>student_pronunciation</th>\n",
       "      <th>syllable_number</th>\n",
       "      <th>prescriptive_syllable</th>\n",
       "      <th>student_syllable</th>\n",
       "      <th>correct_allophone</th>\n",
       "      <th>student_allophone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>0</td>\n",
       "      <td>kom</td>\n",
       "      <td>kom</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>1</td>\n",
       "      <td>bi</td>\n",
       "      <td>bi</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>2</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>kom-bi-na-si̯on</td>\n",
       "      <td>3</td>\n",
       "      <td>si̯on</td>\n",
       "      <td>si̯on</td>\n",
       "      <td>i̯o</td>\n",
       "      <td>i̯o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>e-ðu-ka-si̯on</td>\n",
       "      <td>e-du-ka-si̯on</td>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>e-ðu-ka-si̯on</td>\n",
       "      <td>e-du-ka-si̯on</td>\n",
       "      <td>1</td>\n",
       "      <td>ðu</td>\n",
       "      <td>du</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>e-ðu-ka-si̯on</td>\n",
       "      <td>e-du-ka-si̯on</td>\n",
       "      <td>2</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>e-ðu-ka-si̯on</td>\n",
       "      <td>e-du-ka-si̯on</td>\n",
       "      <td>3</td>\n",
       "      <td>si̯on</td>\n",
       "      <td>si̯on</td>\n",
       "      <td>i̯o</td>\n",
       "      <td>i̯o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>u-saɾ</td>\n",
       "      <td>u-saɾ</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>u-saɾ</td>\n",
       "      <td>u-saɾ</td>\n",
       "      <td>1</td>\n",
       "      <td>saɾ</td>\n",
       "      <td>saɾ</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>fun-si̯o-naɾ</td>\n",
       "      <td>fun-si̯o-naɾ</td>\n",
       "      <td>0</td>\n",
       "      <td>fun</td>\n",
       "      <td>fun</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>fun-si̯o-naɾ</td>\n",
       "      <td>fun-si̯o-naɾ</td>\n",
       "      <td>1</td>\n",
       "      <td>si̯o</td>\n",
       "      <td>si̯o</td>\n",
       "      <td>i̯o</td>\n",
       "      <td>i̯o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>fun-si̯o-naɾ</td>\n",
       "      <td>fun-si̯o-naɾ</td>\n",
       "      <td>2</td>\n",
       "      <td>naɾ</td>\n",
       "      <td>naɾ</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>14</td>\n",
       "      <td>o-poɾ-tu-ni-ðað</td>\n",
       "      <td>o-poɾ-tu-ni-dað</td>\n",
       "      <td>0</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14</td>\n",
       "      <td>o-poɾ-tu-ni-ðað</td>\n",
       "      <td>o-poɾ-tu-ni-dað</td>\n",
       "      <td>1</td>\n",
       "      <td>poɾ</td>\n",
       "      <td>poɾ</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14</td>\n",
       "      <td>o-poɾ-tu-ni-ðað</td>\n",
       "      <td>o-poɾ-tu-ni-dað</td>\n",
       "      <td>2</td>\n",
       "      <td>tu</td>\n",
       "      <td>tu</td>\n",
       "      <td>u</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14</td>\n",
       "      <td>o-poɾ-tu-ni-ðað</td>\n",
       "      <td>o-poɾ-tu-ni-dað</td>\n",
       "      <td>3</td>\n",
       "      <td>ni</td>\n",
       "      <td>ni</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14</td>\n",
       "      <td>o-poɾ-tu-ni-ðað</td>\n",
       "      <td>o-poɾ-tu-ni-dað</td>\n",
       "      <td>4</td>\n",
       "      <td>ðað</td>\n",
       "      <td>dað</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>21</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>0</td>\n",
       "      <td>im</td>\n",
       "      <td>im</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>21</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>1</td>\n",
       "      <td>poɾ</td>\n",
       "      <td>poɾ</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>21</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>2</td>\n",
       "      <td>tan</td>\n",
       "      <td>tan</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>21</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>im-poɾ-tan-te</td>\n",
       "      <td>3</td>\n",
       "      <td>te</td>\n",
       "      <td>te</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_number prescriptive_pronunciation student_pronunciation  \\\n",
       "2             1            kom-bi-na-si̯on       kom-bi-na-si̯on   \n",
       "3             1            kom-bi-na-si̯on       kom-bi-na-si̯on   \n",
       "4             1            kom-bi-na-si̯on       kom-bi-na-si̯on   \n",
       "5             1            kom-bi-na-si̯on       kom-bi-na-si̯on   \n",
       "9             3              e-ðu-ka-si̯on         e-du-ka-si̯on   \n",
       "10            3              e-ðu-ka-si̯on         e-du-ka-si̯on   \n",
       "11            3              e-ðu-ka-si̯on         e-du-ka-si̯on   \n",
       "12            3              e-ðu-ka-si̯on         e-du-ka-si̯on   \n",
       "19            7                      u-saɾ                 u-saɾ   \n",
       "20            7                      u-saɾ                 u-saɾ   \n",
       "21            8               fun-si̯o-naɾ          fun-si̯o-naɾ   \n",
       "22            8               fun-si̯o-naɾ          fun-si̯o-naɾ   \n",
       "23            8               fun-si̯o-naɾ          fun-si̯o-naɾ   \n",
       "35           14            o-poɾ-tu-ni-ðað       o-poɾ-tu-ni-dað   \n",
       "36           14            o-poɾ-tu-ni-ðað       o-poɾ-tu-ni-dað   \n",
       "37           14            o-poɾ-tu-ni-ðað       o-poɾ-tu-ni-dað   \n",
       "38           14            o-poɾ-tu-ni-ðað       o-poɾ-tu-ni-dað   \n",
       "39           14            o-poɾ-tu-ni-ðað       o-poɾ-tu-ni-dað   \n",
       "51           21              im-poɾ-tan-te         im-poɾ-tan-te   \n",
       "52           21              im-poɾ-tan-te         im-poɾ-tan-te   \n",
       "53           21              im-poɾ-tan-te         im-poɾ-tan-te   \n",
       "54           21              im-poɾ-tan-te         im-poɾ-tan-te   \n",
       "\n",
       "    syllable_number prescriptive_syllable student_syllable correct_allophone  \\\n",
       "2                 0                   kom              kom                 o   \n",
       "3                 1                    bi               bi                 i   \n",
       "4                 2                    na               na                 a   \n",
       "5                 3                 si̯on            si̯on               i̯o   \n",
       "9                 0                     e                e                 e   \n",
       "10                1                    ðu               du                 u   \n",
       "11                2                    ka               ka                 a   \n",
       "12                3                 si̯on            si̯on               i̯o   \n",
       "19                0                     u                u                 u   \n",
       "20                1                   saɾ              saɾ                 a   \n",
       "21                0                   fun              fun                 u   \n",
       "22                1                  si̯o             si̯o               i̯o   \n",
       "23                2                   naɾ              naɾ                 a   \n",
       "35                0                     o                o                 o   \n",
       "36                1                   poɾ              poɾ                 o   \n",
       "37                2                    tu               tu                 u   \n",
       "38                3                    ni               ni                 i   \n",
       "39                4                   ðað              dað                 a   \n",
       "51                0                    im               im                 i   \n",
       "52                1                   poɾ              poɾ                 o   \n",
       "53                2                   tan              tan                 a   \n",
       "54                3                    te               te                 e   \n",
       "\n",
       "   student_allophone  \n",
       "2                  o  \n",
       "3                  i  \n",
       "4                  a  \n",
       "5                i̯o  \n",
       "9                  e  \n",
       "10                 u  \n",
       "11                 a  \n",
       "12               i̯o  \n",
       "19                 u  \n",
       "20                 a  \n",
       "21                 u  \n",
       "22               i̯o  \n",
       "23                 a  \n",
       "35                 o  \n",
       "36                 o  \n",
       "37                 u  \n",
       "38                 i  \n",
       "39                 a  \n",
       "51                 i  \n",
       "52                 o  \n",
       "53                 a  \n",
       "54                 e  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def averages(dictionary_df, column_criteria, equivelancy_criteria, ls_of_dfs):\n",
    "words = dictionary[dictionary['cognate'] == 1]\n",
    "print(words)\n",
    "df = dfs[1]\n",
    "df[df['word_number'].isin(words['list_number'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
